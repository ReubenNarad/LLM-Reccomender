{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a539b59f-a832-49db-993a-389049c7fcda",
   "metadata": {},
   "source": [
    "# Execute GPT requests with RAG\n",
    "\n",
    "- TODO: Format different function calls in ./tools/templates\n",
    "- TODO: Preprocess data from non-movie sets\n",
    "- TODO: Make gpt call separate module, to swap out with local LLM\n",
    "- TODO: Add better eval metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5696aaae-ad0a-442d-9013-85da601fc853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install openai langchain -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe56f11e-361a-44b1-9dcb-c0e4d495eaa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, recall_score, roc_auc_score\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import sys\n",
    "sys.path.append('tools')\n",
    "\n",
    "from utils import *\n",
    "import openai_chains\n",
    "import local_llm_chains\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load api key\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "710345af-0dff-42c6-a873-4dca71062e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve samples at random from formatted dataset\n",
    "sample_size = 500\n",
    "data_path = './../data/video/preprocessed_movies.json'\n",
    "\n",
    "rows = extract_rows(sample_size, data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5a1795-3803-4dfd-86ab-6f9f72dc0659",
   "metadata": {},
   "source": [
    "## Define model and function calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e67376-b4ad-41d3-90ee-c3d25af090eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### OpenAI inference and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "626b9812-5d15-4c97-a670-1da5dd6afa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", openai_api_key=openai_api_key, temperature=0)\n",
    "\n",
    "# chain = openai_chains.get_chain('base_explain', model)\n",
    "\n",
    "# pred = []\n",
    "# truth = []\n",
    "# title = []\n",
    "# explanations = []\n",
    "\n",
    "# evaluated = 0\n",
    "\n",
    "# # Run inference on the chain\n",
    "# for i, user in enumerate(rows[5:]):    \n",
    "#     try:\n",
    "#         prefs = format_preferences(user)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error: {e} for user {user}\")\n",
    "#     pass\n",
    "        \n",
    "#     # This is where the model is actually called\n",
    "#     response = chain.invoke(prefs)\n",
    "#     prediction = json.loads(response.additional_kwargs['function_call']['arguments'])\n",
    "    \n",
    "#     print(prediction)\n",
    "#     selected_attributes = ['likes', 'dislikes', 'target', 'truth']\n",
    "\n",
    "#     print(json.dumps({attr: prefs[attr] for attr in selected_attributes}, indent=4))\n",
    "#     evaluated += 1\n",
    "#     if evaluated == 2:\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98ac658-918b-48e0-8ff5-834c0980ba3e",
   "metadata": {},
   "source": [
    "### Local Models Inference and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1a8cafd-b8c9-4d1a-8757-b91c47b6a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "875f3c7a-0e60-4942-b6f1-1b0be352daa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb009eb93dd848ebb257df858e2080c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "                                          padding_side='left')\n",
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "                                             load_in_4bit=True,\n",
    "                                             torch_dtype=torch.float16,\n",
    "                                             device_map=\"auto\",\n",
    "                                             cache_dir='/mnt/sdb1/LLM_RecSys/models',\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "022c2665-3008-4b87-9527-0299bec8468c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-rnarad/.local/lib/python3.9/site-packages/bitsandbytes/nn/modules.py:226: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "USER: {\n",
      "    \"likes\": [\n",
      "        \"Young Frankenstein VHS\",\n",
      "        \"Rocketeer VHS\",\n",
      "        \"Hello, Dolly!\",\n",
      "        \"Miss Congeniality / Miss Congeniality 2: Armed and Fabulous\",\n",
      "        \"Sherlock Holmes - A Game Of Shadows Edizione: Regno Unito  ITA italien\",\n",
      "        \"Pitch Perfect\",\n",
      "        \"Olympus has Fallen\",\n",
      "        \"The Avengers (Avengers Assemble) Lenticular Steelbook Blu-ray 3D+2D Region Free Zavvi UK #/4000\"\n",
      "    ],\n",
      "    \"dislikes\": [\n",
      "        \"Ride Along\"\n",
      "    ],\n",
      "    \"target\": \"White House Down\",\n",
      "    \"truth\": true\n",
      "}\n",
      "\n",
      "RESPONSE: \"70\"\n",
      "\n",
      "USER: {\n",
      "    \"likes\": [\n",
      "        \"Gamera\",\n",
      "        \"Blue Man Group: How to Be a Megastar Live!\",\n",
      "        \"Blue Man Group: How to Be a Megastar Live!\",\n",
      "        \"Ultraman: The Complete Series\",\n",
      "        \"Nihombie!: The Complete Japanese Trilogy (Zombie Self-Defense Force / Attack Girls' Swimteam vs. the Undead / Zombie Hunter Rika)\",\n",
      "        \"The Ninja-Thon Collection: Ninja She-Devil / I Was a Teenage Ninja / The Naked Sword\"\n",
      "    ],\n",
      "    \"dislikes\": [],\n",
      "    \"target\": \"Gamera Legacy Collection\",\n",
      "    \"truth\": true\n",
      "}\n",
      "\n",
      "RESPONSE: \"100. The user has already liked 'Gamera', and 'Gamera Legacy Collection' is a collection of Gamera movies. Therefore, it is highly likely that the user will like this movie.\"\n"
     ]
    }
   ],
   "source": [
    "# Retrieve chain and run inference\n",
    "\n",
    "chain = local_llm_chains.get_chain('test', model, tokenizer)\n",
    "\n",
    "evaluated = 0\n",
    "# Run inference on the chain\n",
    "for i, user in enumerate(rows[5:]):    \n",
    "    try:\n",
    "        prefs = format_preferences(user)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e} for user {user}\")\n",
    "    pass\n",
    "        \n",
    "    # This is where the model is actually called\n",
    "    response = chain.invoke(prefs)\n",
    "    \n",
    "    # Prints User\n",
    "    selected_attributes = ['target', 'truth']\n",
    "    # selected_attributes = ['likes', 'dislikes', 'target', 'truth']\n",
    "    print(\"\\nUSER:\", json.dumps({attr: prefs[attr] for attr in selected_attributes}, indent=4))\n",
    "    \n",
    "    print(\"\\nRESPONSE:\", json.dumps(response, indent=4))\n",
    "\n",
    "    \n",
    "    evaluated += 1\n",
    "    if evaluated == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afc47fb3-c21c-419a-bd4a-42a7409916bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=PromptTemplate(input_variables=['dislikes', 'likes', 'target'], template='Below is an instruction that describes a task. Write a response that appropriately completes the request. ### Instruction: You are a movie recommender system.The user has liked {likes}, and disliked {dislikes}. From 0% to 100%, how likely is it that the user will like the following movie: {target}?STRICTLY respond with a number between 0 and 100. ### Response: ') last=HuggingFacePipeline(pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x7fccec684280>)\n"
     ]
    }
   ],
   "source": [
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f2db57-2e18-4453-9653-0a2b0d0dc297",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
